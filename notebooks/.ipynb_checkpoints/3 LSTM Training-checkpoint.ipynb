{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominican-constitution",
   "metadata": {},
   "source": [
    "# LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "contrary-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mobile-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "# def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "#     n_vars = 1 if type(data) is list else data.shape[1]\n",
    "#     df = DataFrame(data)\n",
    "#     cols, names = list(), list()\n",
    "#     # input sequence (t-n, ... t-1)\n",
    "#     for i in range(n_in, 0, -1):\n",
    "#         cols.append(df.shift(i))\n",
    "#         names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "#     # forecast sequence (t, t+1, ... t+n)\n",
    "#     for i in range(0, n_out):\n",
    "#         cols.append(df.shift(-i))\n",
    "#         if i == 0:\n",
    "#             names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "#         else:\n",
    "#             names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "#     # put it all together\n",
    "#     agg = concat(cols, axis=1)\n",
    "#     agg.columns = names\n",
    "#     # drop rows with NaN values\n",
    "#     if dropnan:\n",
    "#         agg.dropna(inplace=True)\n",
    "#     return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "further-binding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.5226481  0.58082193 0.5       ]\n",
      " [0.         0.5261324  0.58082193 0.5       ]\n",
      " [0.         0.5296167  0.58082193 0.5       ]\n",
      " ...\n",
      " [0.05       0.9930314  0.         0.8333334 ]\n",
      " [0.05       0.9965157  0.         0.8333334 ]\n",
      " [0.05       1.         0.         0.8333334 ]]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('../datasets/bss/dublin/reorg/station_2.csv')\n",
    "# dataset = read_csv('datasets/bss/dublin/reorg_plus_weather/station_2.csv')\n",
    "\n",
    "dataset = dataset.drop('TIME', axis=1)\n",
    "# dataset = dataset.drop('date', axis=1)\n",
    "# print(dataset.head())\n",
    "values = dataset.values\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = scaled\n",
    "\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "genetic-abuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 1, 3) (8760,) (8927, 1, 3) (8927,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "# values = reframed.values\n",
    "\n",
    "train_start = 0\n",
    "train_end = 8760\n",
    "\n",
    "test_start = 99144\n",
    "test_end = 108071\n",
    "\n",
    "n_train_hours = 365 * 24\n",
    "train = scaled[train_start:train_end, :]\n",
    "test = scaled[test_start:test_end, :]\n",
    "# train = values[train_start:train_end, :]\n",
    "# test = values[test_start:test_end, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, 1:], train[:, 0]\n",
    "test_X, test_y = test[:, 1:], test[:, 0]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "responsible-reform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "122/122 [==============================] - 5s 11ms/step - loss: 0.2525 - val_loss: 0.2152\n",
      "Epoch 2/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2419 - val_loss: 0.2154\n",
      "Epoch 3/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2405 - val_loss: 0.2159\n",
      "Epoch 4/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2399 - val_loss: 0.2166\n",
      "Epoch 5/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2395 - val_loss: 0.2184\n",
      "Epoch 6/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2400 - val_loss: 0.2188\n",
      "Epoch 7/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2395 - val_loss: 0.2192\n",
      "Epoch 8/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2392 - val_loss: 0.2198\n",
      "Epoch 9/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2391 - val_loss: 0.2207\n",
      "Epoch 10/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2388 - val_loss: 0.2214\n",
      "Epoch 11/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2385 - val_loss: 0.2215\n",
      "Epoch 12/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2378 - val_loss: 0.2224\n",
      "Epoch 13/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2373 - val_loss: 0.2212\n",
      "Epoch 14/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.2364 - val_loss: 0.2205\n",
      "Epoch 15/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2357 - val_loss: 0.2198\n",
      "Epoch 16/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2350 - val_loss: 0.2189\n",
      "Epoch 17/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2342 - val_loss: 0.2180\n",
      "Epoch 18/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2334 - val_loss: 0.2172\n",
      "Epoch 19/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2326 - val_loss: 0.2164\n",
      "Epoch 20/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2317 - val_loss: 0.2154\n",
      "Epoch 21/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2307 - val_loss: 0.2143\n",
      "Epoch 22/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2297 - val_loss: 0.2128\n",
      "Epoch 23/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2285 - val_loss: 0.2110\n",
      "Epoch 24/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.2272 - val_loss: 0.2095\n",
      "Epoch 25/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2260 - val_loss: 0.2076\n",
      "Epoch 26/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2246 - val_loss: 0.2058\n",
      "Epoch 27/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2232 - val_loss: 0.2035\n",
      "Epoch 28/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2218 - val_loss: 0.2016\n",
      "Epoch 29/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2203 - val_loss: 0.1994\n",
      "Epoch 30/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2187 - val_loss: 0.1969\n",
      "Epoch 31/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2170 - val_loss: 0.1945\n",
      "Epoch 32/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2153 - val_loss: 0.1920\n",
      "Epoch 33/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2135 - val_loss: 0.1890\n",
      "Epoch 34/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2116 - val_loss: 0.1866\n",
      "Epoch 35/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2099 - val_loss: 0.1842\n",
      "Epoch 36/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2082 - val_loss: 0.1820\n",
      "Epoch 37/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2065 - val_loss: 0.1792\n",
      "Epoch 38/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.2047 - val_loss: 0.1767\n",
      "Epoch 39/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 0.1747\n",
      "Epoch 40/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.2014 - val_loss: 0.1724\n",
      "Epoch 41/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1999 - val_loss: 0.1701\n",
      "Epoch 42/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1984 - val_loss: 0.1681\n",
      "Epoch 43/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1968 - val_loss: 0.1661\n",
      "Epoch 44/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1951 - val_loss: 0.1646\n",
      "Epoch 45/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1937 - val_loss: 0.1626\n",
      "Epoch 46/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1922 - val_loss: 0.1614\n",
      "Epoch 47/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1910 - val_loss: 0.1602\n",
      "Epoch 48/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1899 - val_loss: 0.1593\n",
      "Epoch 49/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1888 - val_loss: 0.1584\n",
      "Epoch 50/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1880 - val_loss: 0.1573\n",
      "Epoch 51/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1872 - val_loss: 0.1565\n",
      "Epoch 52/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1864 - val_loss: 0.1558\n",
      "Epoch 53/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1858 - val_loss: 0.1553\n",
      "Epoch 54/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1850 - val_loss: 0.1549\n",
      "Epoch 55/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1845 - val_loss: 0.1544\n",
      "Epoch 56/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1841 - val_loss: 0.1542\n",
      "Epoch 57/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1837 - val_loss: 0.1540\n",
      "Epoch 58/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1833 - val_loss: 0.1537\n",
      "Epoch 59/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1830 - val_loss: 0.1536\n",
      "Epoch 60/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1827 - val_loss: 0.1533\n",
      "Epoch 61/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1824 - val_loss: 0.1531\n",
      "Epoch 62/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1822 - val_loss: 0.1530\n",
      "Epoch 63/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1819 - val_loss: 0.1528\n",
      "Epoch 64/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1816 - val_loss: 0.1527\n",
      "Epoch 65/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1813 - val_loss: 0.1526\n",
      "Epoch 66/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1812 - val_loss: 0.1525\n",
      "Epoch 67/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1809 - val_loss: 0.1524\n",
      "Epoch 68/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1807 - val_loss: 0.1522\n",
      "Epoch 69/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1805 - val_loss: 0.1522\n",
      "Epoch 70/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1803 - val_loss: 0.1522\n",
      "Epoch 71/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1802 - val_loss: 0.1522\n",
      "Epoch 72/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1801 - val_loss: 0.1522\n",
      "Epoch 73/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1800 - val_loss: 0.1521\n",
      "Epoch 74/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1799 - val_loss: 0.1521\n",
      "Epoch 75/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1798 - val_loss: 0.1520\n",
      "Epoch 76/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1797 - val_loss: 0.1519\n",
      "Epoch 77/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1796 - val_loss: 0.1519\n",
      "Epoch 78/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1795 - val_loss: 0.1519\n",
      "Epoch 79/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1794 - val_loss: 0.1518\n",
      "Epoch 80/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1793 - val_loss: 0.1518\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1792 - val_loss: 0.1517\n",
      "Epoch 82/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1791 - val_loss: 0.1517\n",
      "Epoch 83/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1790 - val_loss: 0.1517\n",
      "Epoch 84/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1789 - val_loss: 0.1516\n",
      "Epoch 85/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1787 - val_loss: 0.1516\n",
      "Epoch 86/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1787 - val_loss: 0.1516\n",
      "Epoch 87/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1786 - val_loss: 0.1517\n",
      "Epoch 88/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1785 - val_loss: 0.1516\n",
      "Epoch 89/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1784 - val_loss: 0.1516\n",
      "Epoch 90/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1783 - val_loss: 0.1517\n",
      "Epoch 91/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1783 - val_loss: 0.1517\n",
      "Epoch 92/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1782 - val_loss: 0.1517\n",
      "Epoch 93/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1781 - val_loss: 0.1517\n",
      "Epoch 94/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1780 - val_loss: 0.1517\n",
      "Epoch 95/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1779 - val_loss: 0.1518\n",
      "Epoch 96/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1779 - val_loss: 0.1518\n",
      "Epoch 97/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1778 - val_loss: 0.1518\n",
      "Epoch 98/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1778 - val_loss: 0.1518\n",
      "Epoch 99/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1777 - val_loss: 0.1518\n",
      "Epoch 100/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1776 - val_loss: 0.1518\n",
      "Epoch 101/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1776 - val_loss: 0.1518\n",
      "Epoch 102/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1775 - val_loss: 0.1518\n",
      "Epoch 103/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1774 - val_loss: 0.1519\n",
      "Epoch 104/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1774 - val_loss: 0.1518\n",
      "Epoch 105/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1773 - val_loss: 0.1519\n",
      "Epoch 106/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1773 - val_loss: 0.1519\n",
      "Epoch 107/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1772 - val_loss: 0.1519\n",
      "Epoch 108/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1771 - val_loss: 0.1518\n",
      "Epoch 109/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1770 - val_loss: 0.1518\n",
      "Epoch 110/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1770 - val_loss: 0.1518\n",
      "Epoch 111/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1769 - val_loss: 0.1518\n",
      "Epoch 112/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1769 - val_loss: 0.1519\n",
      "Epoch 113/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1769 - val_loss: 0.1520\n",
      "Epoch 114/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1768 - val_loss: 0.1519\n",
      "Epoch 115/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1768 - val_loss: 0.1519\n",
      "Epoch 116/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1768 - val_loss: 0.1521\n",
      "Epoch 117/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1767 - val_loss: 0.1519\n",
      "Epoch 118/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1767 - val_loss: 0.1521\n",
      "Epoch 119/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1767 - val_loss: 0.1521\n",
      "Epoch 120/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1767 - val_loss: 0.1522\n",
      "Epoch 121/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1766 - val_loss: 0.1522\n",
      "Epoch 122/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1766 - val_loss: 0.1522\n",
      "Epoch 123/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1766 - val_loss: 0.1522\n",
      "Epoch 124/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1766 - val_loss: 0.1523\n",
      "Epoch 125/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1766 - val_loss: 0.1523\n",
      "Epoch 126/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1766 - val_loss: 0.1523\n",
      "Epoch 127/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1765 - val_loss: 0.1523\n",
      "Epoch 128/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1765 - val_loss: 0.1523\n",
      "Epoch 129/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1765 - val_loss: 0.1523\n",
      "Epoch 130/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1765 - val_loss: 0.1524\n",
      "Epoch 131/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1765 - val_loss: 0.1524\n",
      "Epoch 132/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1765 - val_loss: 0.1524\n",
      "Epoch 133/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1765 - val_loss: 0.1524\n",
      "Epoch 134/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1764 - val_loss: 0.1524\n",
      "Epoch 135/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1764 - val_loss: 0.1524\n",
      "Epoch 136/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1763 - val_loss: 0.1524\n",
      "Epoch 137/150\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.1764 - val_loss: 0.1524\n",
      "Epoch 138/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1764 - val_loss: 0.1524\n",
      "Epoch 139/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1763 - val_loss: 0.1524\n",
      "Epoch 140/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1763 - val_loss: 0.1525\n",
      "Epoch 141/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1763 - val_loss: 0.1525\n",
      "Epoch 142/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1763 - val_loss: 0.1525\n",
      "Epoch 143/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1762 - val_loss: 0.1525\n",
      "Epoch 144/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1763 - val_loss: 0.1525\n",
      "Epoch 145/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1762 - val_loss: 0.1525\n",
      "Epoch 146/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1762 - val_loss: 0.1525\n",
      "Epoch 147/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1762 - val_loss: 0.1525\n",
      "Epoch 148/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1762 - val_loss: 0.1525\n",
      "Epoch 149/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1761 - val_loss: 0.1526\n",
      "Epoch 150/150\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1761 - val_loss: 0.1526\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y,\n",
    "                    epochs=150,\n",
    "                    batch_size=72,\n",
    "                    validation_data=(test_X, test_y),\n",
    "                    verbose=1,\n",
    "                    shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "palestinian-maintenance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 3.052\n",
      "Test MSE: 17.707\n",
      "Test RMSE: 4.208\n",
      "Test R2: 0.400523587599159847094654196553\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "# print(test_X)\n",
    "# print(yhat)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:, 0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:, 0]\n",
    "# calculate RMSE\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# temp = concatenate((inv_y, inv_yhat))\n",
    "# print(temp)\n",
    "# print(inv_y)\n",
    "# print(inv_yhat)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "mae = mean_absolute_error(inv_y, inv_yhat)\n",
    "mse = mean_squared_error(inv_y, inv_yhat)\n",
    "r2 = r2_score(inv_y, inv_yhat)\n",
    "print('Test MAE: %.3f' % mae)\n",
    "print('Test MSE: %.3f' % mse)\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print('Test R2: %.30f' % r2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
